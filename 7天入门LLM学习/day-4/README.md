# day-4

## 经验总结

方法选型：

- 直接推理：结合提示词工程
  - 适用场景：视模型本身的能力而定，在采用该方式之前需要对现有模型针对自己的业务领域进行较为充分的评估。
  - 准确性：由于是原始模型只接受了通用知识的训练，因此在特定领域的场景下可能存在胡编乱造的可能性（幻觉问题）。使用者需要注意自己的专业场景下是否使用该通用模型能解决所有问题，一般建议直接试用该模型给出模型能力的具体评估。
  - 成本：开发成本较低。如果是开源模型，需要选用合适的硬件及推理方式。这部分在我们教程中的推理章节会有讲解。如果是闭源调用，只需要使用对应模型的接口API即可
  - 缺点：由于模型没有经过针对特有领域的知识，因此效果会比较不可控。比如，在评测时模型表现尚可，但在实际使用中发现模型出现了严重的幻觉和知识匮乏问题，如果是闭源调用则该问题会比较难以解决（可能涉及到工程架构改变），如果是开源模型可以考虑使用训练和RAG的方式解决
- 训练：
  - 适用场景：
    - 常见场景：
      - 场景存在特殊知识，需要进行知识灌注，可以使用继续训练+全量训练
      - 需要对回复的风格或范式进行定制化，可以使用人类对齐训练或微调+全量/轻量训练
      - 模型原有能力不够，如对读入的doc文件进行理解并进行归纳总结，或特有场景的文本进行分类，但原有模型对该任务的回答存在问题，可以使用微调+全量/轻量训练
    - 总结：如果数据是带有规律的，比如文字顺序、逻辑关系、图片元素（比如斑马总是带有黑白色的条纹），那么训练就可以将这些规律抽象出来；如果数据是“无规律的知识”，比如用A解决B问题，用C解决D问题，那么这些数据训练后就几乎不具有泛化性，因为模型无法分析出出现了E问题应该用A解决还是B解决，这时候应当选用RAG或者Agent方式，或者训练的目标改为让模型熟悉使用工具来解决问题
  - 准确性：准确性依照训练的结果而定，训练后模型会按照训练集的风格和方式回答问题。一般来说训练后模型能力会有较大提升，但仍然可能存在幻觉问题。
  - 成本：可以查看SWIFT的benchmark。我们比较了主要模型的训练显存需求和训练速度，用户可以按需评估。
  - 优缺点：
    - 全量训练：全量训练在给定LLM模型上冻结一定的参数（或不冻结任何参数）进行训练，一般耗费显存较高，训练周期比较长。
    - 轻量训练：
      - 主要方案是在模型结构上附着一个额外结构，在训练时冻结原模型并训练额外结构，推理时将额外结构加载起来或合并回原来模型（并不是所有的额外结构都支持合并，支持者比如LoRA，不支持者比如Side）。轻量微调目前的最流行结构是LoRA，该结构理解简单，训练成本较低，在部分任务上可以达到全量微调的效果。
      - 量化：即对模型的float32权重或float16权重进行缩放，使其变成int类型的整形，节省显存或计算时长。
    - 相比RAG，输出可解释性不强
    - 存在幻觉问题
    - 在精确问答场景上可能会产出非专业结果（如法律行业）
    - 对知识更新频繁的场景不适用
- RAG：
  - 适用场景：
    - 需要根据语料精确回答，比如法律或医疗领域
    - 搜索召回场景，比如搜索引擎
    - 知识频繁更新，灵活性较强的场景
  - 准确性：准确性较高，可解释性也较高
  - 成本：除模型本身的成本外，需要额外的向量数据库和工程端开发成本和维护成本
  - 缺点：
    - 比模型直接回答多了查询召回步骤，单请求整体RT高一些
    - 如果场景和知识无关，比如非知识类问答，或API调用，或文档分析，文章总结等，RAG就不能起到作用
- Agent：
  - 适用场景：复杂的应用场景，需要模型产生思维过程，将整体任务拆分为具体任务进行执行，比如包含了运行代码、接口调用等过程

模型选型：

- Agent场景尽量选择较大的模型或者闭源LLM API（如GPT4、Qwen-max）
- 训练场景中，数据量较大（比如大于10000条）、数据质量较高、专业度较高的训练优先选择base模型，数据量较少优先选择chat模型。在算力允许条件下可以进行对比训练实验
- 关注国内外的开源可信模型榜单，选择排名较高或口碑较好的模型

分布式训练：

- DDP：
- MP

## py-torch

### 梯度的定义
梯度是一个向量，表示多元函数在某一点处的变化率和方向。对于一个标量函数 $ f(x_1, x_2, ..., x_n) $，其梯度记为：

$$
\nabla f = \left[ \frac{\partial f}{\partial x_1}, \frac{\partial f}{\partial x_2}, ..., \frac{\partial f}{\partial x_n} \right]
$$

- 每个分量是函数对某个变量的偏导数。
- 梯度的方向是函数值增长最快的方向，大小是变化率。

---

### 在深度学习中的意义
在深度学习中，梯度用于优化模型参数（如权重和偏置）。通过计算损失函数对参数的梯度，可以使用梯度下降等优化算法更新参数，使损失函数逐渐减小。

---

### 示例解释
在你的代码中：
```python
a = torch.tensor([1.], requires_grad=True)
b = torch.tensor([2.], requires_grad=True)
c = a * b
```
- 定义了两个张量 `a` 和 `b`，并设置 `requires_grad=True`，表示需要计算它们的梯度。
- 计算 `c = a * b`，即 $ c = a \cdot b $。
- 调用 `c.backward()` 时，PyTorch 自动计算 $ c $ 对 $ a $ 和 $ b $ 的偏导数：
  - $ \frac{\partial c}{\partial a} = b $
  - $ \frac{\partial c}{\partial b} = a $

最终结果：
- `a.grad` 是 $ \frac{\partial c}{\partial a} $，值为 `[2.]`。
- `b.grad` 是 $ \frac{\partial c}{\partial b} $，值为 `[1.]`。

---

### 总结
梯度是函数变化率的核心概念，在深度学习中用于指导参数更新，优化模型性能。
